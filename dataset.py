import torch
import numpy as np
import pandas as pd
from torch.utils.data import Dataset
import os


class DeltaTSequenceDataset(Dataset):
    def __init__(self, config, is_train=True):
        self.seq_len = 1024  # å›ºå®šåºåˆ—é•¿åº¦ï¼Œä¾‹å¦‚æ¯æ¬¡å– 1024 ä¸ªé—´éš”
        self.samples = []

        print(f"ğŸš€ åˆå§‹åŒ– Delta-T æ•°æ®é›† ({'è®­ç»ƒ' if is_train else 'æµ‹è¯•'})...")

        # åŠ è½½æ•°æ®é€»è¾‘ (ç®€åŒ–ç‰ˆï¼Œè¯·æ ¹æ®å®é™…æ–‡ä»¶è·¯å¾„è¡¥å…¨)
        # å‡è®¾ config['files'] åŒ…å«æ¸…æ´—åçš„ .npy æ–‡ä»¶è·¯å¾„
        target_files = config['files_train'] if is_train else config['files_test']

        for file_path in target_files:
            try:
                # åŠ è½½æ¸…æ´—åçš„æ•°æ® [x, y, p, t] (è¿™é‡Œå‡è®¾ä½ å·²ç»æ¸…æ´—å¹¶ä¿å­˜äº†)
                # æ³¨æ„ï¼šå¦‚æœæ˜¯ csvï¼ŒæŒ‰ä½ çš„æ–°æ ¼å¼ï¼šcol(0), row(1), t_in(2), t_ex(3)
                if file_path.endswith('.csv'):
                    df = pd.read_csv(file_path, header=None, usecols=[2], names=['t_in'])
                    t_seq = df['t_in'].values.astype(np.float32)
                else:  # .npy
                    data = np.load(file_path)
                    # å‡è®¾ npy ä¹Ÿæ˜¯å­˜çš„ [col, row, t_in, t_ex]
                    t_seq = data[:, 2]

                    # è®¡ç®— Delta t
                # æ’åºæ˜¯å¿…é¡»çš„ï¼Œè™½ç„¶ç‰©ç†äº§ç”Ÿæ—¶å°±æ˜¯æœ‰åºçš„ï¼Œä½†ä¿é™©èµ·è§
                t_seq = np.sort(t_seq)
                delta_t = np.diff(t_seq)

                # ğŸŒŸ å…³é”®é¢„å¤„ç†ï¼šLog å˜æ¢ + å½’ä¸€åŒ–
                # log(dt) èƒ½æŠŠè·¨åº¦å·¨å¤§çš„å¾®ç§’çº§å·®å¼‚å‹ç¼©åˆ°åˆç†èŒƒå›´
                # åŠ  1.0 æ˜¯ä¸ºäº†é˜²æ­¢ dt=0 å¯¼è‡´ log è´Ÿæ— ç©·
                delta_t = np.log1p(delta_t)

                # åˆ‡åˆ†æˆæ ·æœ¬
                num_samples = len(delta_t) // self.seq_len
                for i in range(num_samples):
                    segment = delta_t[i * self.seq_len: (i + 1) * self.seq_len]

                    # è·å–è¯¥æ®µæ•°æ®çš„çœŸå®æµé€Ÿæ ‡ç­¾ (ä»æ–‡ä»¶åè§£æ)
                    # æ¯”å¦‚ "0.2mm_1.csv" -> 0.2
                    label = self.parse_velocity_from_name(file_path)

                    self.samples.append({
                        'dt_seq': segment,
                        'label': label
                    })
            except Exception as e:
                print(f"âŒ Error loading {file_path}: {e}")

            # ... (åŠ è½½å¾ªç¯ç»“æŸ) ...
            print(f"âœ… åŠ è½½å®Œæˆ: å…± {len(self.samples)} ä¸ªæ ·æœ¬")

            # ğŸŒŸ æ–°å¢ï¼šæ£€æŸ¥æ ‡ç­¾æœ‰æ²¡æœ‰è¯»å¯¹
            labels = [s['label'] for s in self.samples]
            print(f"ğŸ“Š æ ‡ç­¾åˆ†å¸ƒæ£€æŸ¥: Min={min(labels)}, Max={max(labels)}")
            print(f"   æ ·ä¾‹æ ‡ç­¾: {labels[:10]}")

    def parse_velocity_from_name(self, path):
        # ç®€å•çš„æ–‡ä»¶åè§£æé€»è¾‘
        name = os.path.basename(path)
        if "0.2" in name: return 0.2
        if "0.5" in name: return 0.5
        if "0.8" in name: return 0.8
        if "1.0" in name: return 1.0
        if "1.2" in name: return 1.2
        if "1.5" in name: return 1.5
        if "1.8" in name: return 1.8
        if "2.0" in name: return 2.0
        if "2.2" in name: return 2.2
        if "2.5" in name: return 2.5
        return 0.0

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        item = self.samples[idx]
        x = torch.from_numpy(item['data']).float().unsqueeze(0)

        # ğŸŒŸ ä¿®æ”¹ç‚¹ï¼šå¯¹æ ‡ç­¾è¿›è¡Œå½’ä¸€åŒ–
        # å‡è®¾æœ€å¤§æµé€Ÿæ˜¯ 2.5 mm/s (æˆ–è€…ä½ é¢„è®¡çš„æœ€å¤§å€¼æ¯”å¦‚ 3.0)
        # è¿™æ · label å°±å˜æˆäº† 0.0 ~ 1.0 ä¹‹é—´ï¼Œè¿™å¯¹ç¥ç»ç½‘ç»œæ›´å‹å¥½
        raw_label = item['label']
        normalized_label = raw_label / 2.5

        y = torch.tensor([normalized_label], dtype=torch.float32)
        return x, y